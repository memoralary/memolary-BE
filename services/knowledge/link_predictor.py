"""
Knowledge Graph Link Prediction with PyTorch Geometric

Django DBì˜ ì§€ì‹ ê·¸ë˜í”„ë¥¼ ì²˜ë¦¬í•˜ê³ , ì‚¬ìš©ìê°€ ë‹¤ìŒì— í•™ìŠµí•  ë…¸ë“œë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    from services.knowledge.link_predictor import LinkPredictor, GraphDataLoader
    
    # ë°ì´í„° ë¡œë“œ
    loader = GraphDataLoader()
    data = loader.load_from_db()
    
    # ëª¨ë¸ í•™ìŠµ
    predictor = LinkPredictor(embedding_dim=384)
    predictor.train(data)
    
    # ë‹¤ìŒ í•™ìŠµ ë…¸ë“œ ì˜ˆì¸¡
    next_nodes = predictor.predict_next_nodes(current_node_id, top_k=5)
"""

import logging
import pickle
from typing import List, Dict, Tuple, Optional, Any
from dataclasses import dataclass

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv, SAGEConv, GATConv
from torch_geometric.utils import negative_sampling

logger = logging.getLogger(__name__)


# =============================================================================
# Graph Data Loader
# =============================================================================

@dataclass
class GraphData:
    """ê·¸ë˜í”„ ë°ì´í„° ì»¨í…Œì´ë„ˆ"""
    x: torch.Tensor                    # ë…¸ë“œ íŠ¹ì„± (N, D)
    edge_index: torch.Tensor           # ì—£ì§€ ì¸ë±ìŠ¤ (2, E)
    edge_attr: Optional[torch.Tensor]  # ì—£ì§€ íŠ¹ì„± (E, F)
    node_ids: List[str]                # ë…¸ë“œ ID ë¦¬ìŠ¤íŠ¸ (UUID)
    node_titles: List[str]             # ë…¸ë“œ ì œëª© ë¦¬ìŠ¤íŠ¸
    id_to_idx: Dict[str, int]          # ID -> ì¸ë±ìŠ¤ ë§¤í•‘
    
    @property
    def num_nodes(self) -> int:
        return self.x.shape[0]
    
    @property
    def num_edges(self) -> int:
        return self.edge_index.shape[1]
    
    @property
    def embedding_dim(self) -> int:
        return self.x.shape[1]
    
    def to_pyg_data(self) -> Data:
        """PyTorch Geometric Data ê°ì²´ë¡œ ë³€í™˜"""
        return Data(
            x=self.x,
            edge_index=self.edge_index,
            edge_attr=self.edge_attr,
            num_nodes=self.num_nodes
        )


class GraphDataLoader:
    """
    Django DBì—ì„œ ê·¸ë˜í”„ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, default_embedding_dim: int = 384):
        self.default_embedding_dim = default_embedding_dim
    
    def load_from_db(self) -> GraphData:
        """
        Django DBì—ì„œ ë…¸ë“œì™€ ì—£ì§€ë¥¼ ë¡œë“œí•˜ì—¬ GraphData ìƒì„±
        
        UUID ë³€í™˜ ì˜¤ë¥˜ê°€ ìˆëŠ” ë°ì´í„°ëŠ” ë¬´ì‹œí•˜ê³  ì•ˆì „í•˜ê²Œ ë¡œë“œí•©ë‹ˆë‹¤.
        """
        from django.db import connection
        
        # Raw SQLë¡œ ì•ˆì „í•˜ê²Œ ë…¸ë“œ ë¡œë“œ (UUID ë³€í™˜ ì˜¤ë¥˜ ë°©ì§€)
        nodes_data = []
        try:
            with connection.cursor() as cursor:
                cursor.execute("""
                    SELECT id, title, description, embedding, cluster_id 
                    FROM knowledge_knowledgenode
                """)
                columns = [col[0] for col in cursor.description]
                for row in cursor.fetchall():
                    node_dict = dict(zip(columns, row))
                    nodes_data.append(node_dict)
        except Exception as e:
            logger.error(f"ë…¸ë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return self._create_empty_graph()
        
        if not nodes_data:
            logger.warning("DBì— ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            return self._create_empty_graph()
        
        # ìœ íš¨í•œ ë…¸ë“œë§Œ í•„í„°ë§
        valid_nodes = []
        for node in nodes_data:
            try:
                node_id = str(node['id']) if node['id'] else None
                if node_id and node.get('title'):
                    valid_nodes.append({
                        'id': node_id,
                        'title': node['title'],
                        'description': node.get('description', ''),
                        'embedding': node.get('embedding'),
                    })
            except Exception as e:
                logger.warning(f"ë…¸ë“œ íŒŒì‹± ìŠ¤í‚µ (ì˜ëª»ëœ í˜•ì‹): {e}")
                continue
        
        if len(valid_nodes) < 2:
            logger.warning(f"ìœ íš¨í•œ ë…¸ë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ ({len(valid_nodes)}ê°œ). ìµœì†Œ 2ê°œ í•„ìš”.")
            return self._create_empty_graph()
        
        logger.info(f"ìœ íš¨í•œ ë…¸ë“œ {len(valid_nodes)}ê°œ ë¡œë“œë¨")
        
        # ID -> ì¸ë±ìŠ¤ ë§¤í•‘
        node_ids = [n['id'] for n in valid_nodes]
        node_titles = [n['title'] for n in valid_nodes]
        id_to_idx = {nid: idx for idx, nid in enumerate(node_ids)}
        
        # ë…¸ë“œ ì„ë² ë”© ì¶”ì¶œ
        import pickle
        embeddings = []
        for node in valid_nodes:
            emb_data = node.get('embedding')
            emb = None
            
            if emb_data:
                try:
                    if isinstance(emb_data, bytes):
                        emb = pickle.loads(emb_data)
                    elif isinstance(emb_data, memoryview):
                        emb = pickle.loads(bytes(emb_data))
                except Exception as e:
                    logger.debug(f"ì„ë² ë”© ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            if emb is not None:
                embeddings.append(emb)
            else:
                # ì„ë² ë”©ì´ ì—†ìœ¼ë©´ ëœë¤ ì´ˆê¸°í™”
                embeddings.append(
                    np.random.randn(self.default_embedding_dim).astype(np.float32)
                )
        
        x = torch.tensor(np.stack(embeddings), dtype=torch.float32)
        
        # Raw SQLë¡œ ì—£ì§€ ë¡œë“œ
        edges_data = []
        try:
            with connection.cursor() as cursor:
                cursor.execute("""
                    SELECT source_id, target_id, confidence 
                    FROM knowledge_knowledgeedge
                """)
                for row in cursor.fetchall():
                    edges_data.append({
                        'source_id': str(row[0]) if row[0] else None,
                        'target_id': str(row[1]) if row[1] else None,
                        'confidence': float(row[2]) if row[2] else 1.0,
                    })
        except Exception as e:
            logger.warning(f"ì—£ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            edges_data = []
        
        if not edges_data:
            logger.warning("DBì— ì—£ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì—ëŠ” ìµœì†Œ 2ê°œì˜ ì—£ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            edge_index = torch.zeros((2, 0), dtype=torch.long)
            edge_attr = None
        else:
            source_indices = []
            target_indices = []
            confidences = []
            
            for edge in edges_data:
                src_id = edge.get('source_id')
                tgt_id = edge.get('target_id')
                
                if src_id and tgt_id and src_id in id_to_idx and tgt_id in id_to_idx:
                    source_indices.append(id_to_idx[src_id])
                    target_indices.append(id_to_idx[tgt_id])
                    confidences.append(edge.get('confidence', 1.0))
            
            if not source_indices:
                logger.warning("ìœ íš¨í•œ ì—£ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
                edge_index = torch.zeros((2, 0), dtype=torch.long)
                edge_attr = None
            else:
                edge_index = torch.tensor(
                    [source_indices, target_indices],
                    dtype=torch.long
                )
                edge_attr = torch.tensor(confidences, dtype=torch.float32).unsqueeze(1)
        
        logger.info(f"ê·¸ë˜í”„ ë¡œë“œ ì™„ë£Œ: {len(valid_nodes)}ê°œ ë…¸ë“œ, {edge_index.shape[1]}ê°œ ì—£ì§€")
        
        # í•™ìŠµ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if edge_index.shape[1] < 2:
            logger.warning("âš ï¸  ì—£ì§€ê°€ 2ê°œ ë¯¸ë§Œì´ë©´ Link Prediction í•™ìŠµì´ ì–´ë µìŠµë‹ˆë‹¤.")
        
        return GraphData(
            x=x,
            edge_index=edge_index,
            edge_attr=edge_attr,
            node_ids=node_ids,
            node_titles=node_titles,
            id_to_idx=id_to_idx
        )
    
    def _create_empty_graph(self) -> GraphData:
        """ë¹ˆ ê·¸ë˜í”„ ìƒì„±"""
        return GraphData(
            x=torch.zeros((0, self.default_embedding_dim), dtype=torch.float32),
            edge_index=torch.zeros((2, 0), dtype=torch.long),
            edge_attr=None,
            node_ids=[],
            node_titles=[],
            id_to_idx={}
        )
    
    @staticmethod
    def create_sample_graph(
        num_nodes: int = 5,
        embedding_dim: int = 64,
        edge_probability: float = 0.4
    ) -> GraphData:
        """
        í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ê·¸ë˜í”„ ìƒì„±
        
        Args:
            num_nodes: ë…¸ë“œ ìˆ˜
            embedding_dim: ì„ë² ë”© ì°¨ì›
            edge_probability: ì—£ì§€ ìƒì„± í™•ë¥ 
            
        Returns:
            ìƒ˜í”Œ GraphData
        """
        # ëœë¤ ë…¸ë“œ ì„ë² ë”©
        x = torch.randn(num_nodes, embedding_dim)
        
        # ëœë¤ ì—£ì§€ ìƒì„± (ErdÅ‘s-RÃ©nyi)
        source_indices = []
        target_indices = []
        
        for i in range(num_nodes):
            for j in range(num_nodes):
                if i != j and np.random.random() < edge_probability:
                    source_indices.append(i)
                    target_indices.append(j)
        
        edge_index = torch.tensor([source_indices, target_indices], dtype=torch.long)
        
        # ë…¸ë“œ ë©”íƒ€ë°ì´í„°
        node_ids = [f"node_{i}" for i in range(num_nodes)]
        node_titles = [f"Concept {i}" for i in range(num_nodes)]
        id_to_idx = {nid: idx for idx, nid in enumerate(node_ids)}
        
        return GraphData(
            x=x,
            edge_index=edge_index,
            edge_attr=None,
            node_ids=node_ids,
            node_titles=node_titles,
            id_to_idx=id_to_idx
        )


# =============================================================================
# GNN Encoder Models
# =============================================================================

class GCNEncoder(nn.Module):
    """Graph Convolutional Network ì¸ì½”ë”"""
    
    def __init__(
        self,
        in_channels: int,
        hidden_channels: int,
        out_channels: int,
        num_layers: int = 2,
        dropout: float = 0.5
    ):
        super().__init__()
        
        self.convs = nn.ModuleList()
        self.convs.append(GCNConv(in_channels, hidden_channels))
        
        for _ in range(num_layers - 2):
            self.convs.append(GCNConv(hidden_channels, hidden_channels))
        
        if num_layers > 1:
            self.convs.append(GCNConv(hidden_channels, out_channels))
        
        self.dropout = dropout
    
    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        for i, conv in enumerate(self.convs[:-1]):
            x = conv(x, edge_index)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        
        x = self.convs[-1](x, edge_index)
        return x


class SAGEEncoder(nn.Module):
    """GraphSAGE ì¸ì½”ë”"""
    
    def __init__(
        self,
        in_channels: int,
        hidden_channels: int,
        out_channels: int,
        num_layers: int = 2,
        dropout: float = 0.5
    ):
        super().__init__()
        
        self.convs = nn.ModuleList()
        self.convs.append(SAGEConv(in_channels, hidden_channels))
        
        for _ in range(num_layers - 2):
            self.convs.append(SAGEConv(hidden_channels, hidden_channels))
        
        if num_layers > 1:
            self.convs.append(SAGEConv(hidden_channels, out_channels))
        
        self.dropout = dropout
    
    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        for i, conv in enumerate(self.convs[:-1]):
            x = conv(x, edge_index)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
        
        x = self.convs[-1](x, edge_index)
        return x


# =============================================================================
# Link Prediction Decoder
# =============================================================================

class LinkDecoder(nn.Module):
    """
    ë§í¬ ì˜ˆì¸¡ ë””ì½”ë”
    
    ë‘ ë…¸ë“œ ì„ë² ë”©ì„ ë°›ì•„ ë§í¬ ì¡´ì¬ í™•ë¥ ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, hidden_channels: int, method: str = "dot"):
        super().__init__()
        self.method = method
        
        if method == "mlp":
            self.mlp = nn.Sequential(
                nn.Linear(hidden_channels * 2, hidden_channels),
                nn.ReLU(),
                nn.Dropout(0.5),
                nn.Linear(hidden_channels, 1)
            )
    
    def forward(
        self,
        z: torch.Tensor,
        edge_index: torch.Tensor
    ) -> torch.Tensor:
        """
        Args:
            z: ë…¸ë“œ ì„ë² ë”© (N, D)
            edge_index: ì˜ˆì¸¡í•  ì—£ì§€ (2, E)
            
        Returns:
            ë§í¬ í™•ë¥  (E,)
        """
        src = z[edge_index[0]]
        tgt = z[edge_index[1]]
        
        if self.method == "dot":
            # ë‚´ì  ê¸°ë°˜
            return (src * tgt).sum(dim=1)
        elif self.method == "cosine":
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            return F.cosine_similarity(src, tgt)
        elif self.method == "mlp":
            # MLP ê¸°ë°˜
            return self.mlp(torch.cat([src, tgt], dim=1)).squeeze()
        else:
            raise ValueError(f"Unknown method: {self.method}")


# =============================================================================
# Link Prediction Model
# =============================================================================

class LinkPredictionModel(nn.Module):
    """
    Link Prediction ì „ì²´ ëª¨ë¸
    
    GNN ì¸ì½”ë” + ë§í¬ ë””ì½”ë”ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        in_channels: int,
        hidden_channels: int = 128,
        out_channels: int = 64,
        encoder_type: str = "sage",
        decoder_type: str = "dot",
        num_layers: int = 2,
        dropout: float = 0.5
    ):
        super().__init__()
        
        # ì¸ì½”ë” ì„ íƒ
        if encoder_type == "gcn":
            self.encoder = GCNEncoder(
                in_channels, hidden_channels, out_channels, num_layers, dropout
            )
        elif encoder_type == "sage":
            self.encoder = SAGEEncoder(
                in_channels, hidden_channels, out_channels, num_layers, dropout
            )
        else:
            raise ValueError(f"Unknown encoder: {encoder_type}")
        
        # ë””ì½”ë”
        self.decoder = LinkDecoder(out_channels, decoder_type)
        
        self.out_channels = out_channels
    
    def encode(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        """ë…¸ë“œ ì„ë² ë”© ìƒì„±"""
        return self.encoder(x, edge_index)
    
    def decode(self, z: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:
        """ë§í¬ í™•ë¥  ì˜ˆì¸¡"""
        return self.decoder(z, edge_index)
    
    def forward(
        self,
        x: torch.Tensor,
        edge_index: torch.Tensor,
        pos_edge_index: torch.Tensor,
        neg_edge_index: torch.Tensor
    ) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        ìˆœì „íŒŒ
        
        Returns:
            (positive_scores, negative_scores)
        """
        z = self.encode(x, edge_index)
        pos_scores = self.decode(z, pos_edge_index)
        neg_scores = self.decode(z, neg_edge_index)
        return pos_scores, neg_scores


# =============================================================================
# Link Predictor (High-level API)
# =============================================================================

class LinkPredictor:
    """
    ë§í¬ ì˜ˆì¸¡ ê³ ìˆ˜ì¤€ API
    
    Django DBì˜ ì§€ì‹ ê·¸ë˜í”„ë¥¼ í•™ìŠµí•˜ê³ , ë‹¤ìŒ í•™ìŠµ ë…¸ë“œë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    
    Example:
        predictor = LinkPredictor(embedding_dim=384)
        predictor.train(graph_data, epochs=100)
        
        next_nodes = predictor.predict_next_nodes("node_id", top_k=5)
    """
    
    def __init__(
        self,
        embedding_dim: int = 384,
        hidden_channels: int = 128,
        out_channels: int = 64,
        encoder_type: str = "sage",
        decoder_type: str = "dot",
        device: Optional[str] = None
    ):
        self.embedding_dim = embedding_dim
        self.hidden_channels = hidden_channels
        self.out_channels = out_channels
        self.encoder_type = encoder_type
        self.decoder_type = decoder_type
        
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        
        self.model: Optional[LinkPredictionModel] = None
        self.graph_data: Optional[GraphData] = None
        self.node_embeddings: Optional[torch.Tensor] = None
    
    def _build_model(self, in_channels: int) -> LinkPredictionModel:
        """ëª¨ë¸ ìƒì„±"""
        return LinkPredictionModel(
            in_channels=in_channels,
            hidden_channels=self.hidden_channels,
            out_channels=self.out_channels,
            encoder_type=self.encoder_type,
            decoder_type=self.decoder_type
        ).to(self.device)
    
    def train(
        self,
        graph_data: GraphData,
        epochs: int = 100,
        lr: float = 0.01,
        weight_decay: float = 1e-5,
        val_ratio: float = 0.1,
        verbose: bool = True
    ) -> Dict[str, List[float]]:
        """
        ëª¨ë¸ í•™ìŠµ
        
        Args:
            graph_data: í•™ìŠµ ë°ì´í„°
            epochs: ì—í¬í¬ ìˆ˜
            lr: í•™ìŠµë¥ 
            weight_decay: L2 ì •ê·œí™”
            val_ratio: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
            verbose: ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€
            
        Returns:
            í•™ìŠµ íˆìŠ¤í† ë¦¬ {"train_loss": [...], "val_auc": [...]}
        """
        self.graph_data = graph_data
        
        if graph_data.num_edges == 0:
            logger.warning("ì—£ì§€ê°€ ì—†ì–´ í•™ìŠµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return {"train_loss": [], "val_auc": []}
        
        # ëª¨ë¸ ìƒì„±
        self.model = self._build_model(graph_data.embedding_dim)
        
        # ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        x = graph_data.x.to(self.device)
        edge_index = graph_data.edge_index.to(self.device)
        
        # Train/Val ë¶„í• 
        num_edges = edge_index.shape[1]
        num_val = max(1, int(num_edges * val_ratio))
        
        perm = torch.randperm(num_edges)
        val_mask = perm[:num_val]
        train_mask = perm[num_val:]
        
        train_edge_index = edge_index[:, train_mask]
        val_edge_index = edge_index[:, val_mask]
        
        # ì˜µí‹°ë§ˆì´ì €
        optimizer = torch.optim.Adam(
            self.model.parameters(), lr=lr, weight_decay=weight_decay
        )
        
        history = {"train_loss": [], "val_auc": []}
        
        for epoch in range(epochs):
            self.model.train()
            optimizer.zero_grad()
            
            # Negative sampling
            neg_edge_index = negative_sampling(
                edge_index=train_edge_index,
                num_nodes=graph_data.num_nodes,
                num_neg_samples=train_edge_index.shape[1]
            )
            
            # Forward
            pos_scores, neg_scores = self.model(
                x, train_edge_index, train_edge_index, neg_edge_index
            )
            
            # Binary cross-entropy loss
            pos_loss = F.binary_cross_entropy_with_logits(
                pos_scores, torch.ones_like(pos_scores)
            )
            neg_loss = F.binary_cross_entropy_with_logits(
                neg_scores, torch.zeros_like(neg_scores)
            )
            loss = pos_loss + neg_loss
            
            loss.backward()
            optimizer.step()
            
            history["train_loss"].append(loss.item())
            
            # ê²€ì¦
            if (epoch + 1) % 10 == 0 and verbose:
                val_auc = self._evaluate(x, train_edge_index, val_edge_index)
                history["val_auc"].append(val_auc)
                logger.info(f"Epoch {epoch+1}/{epochs}: Loss={loss.item():.4f}, Val_AUC={val_auc:.4f}")
        
        # ìµœì¢… ë…¸ë“œ ì„ë² ë”© ì €ì¥
        self.model.eval()
        with torch.no_grad():
            self.node_embeddings = self.model.encode(x, edge_index)
        
        return history
    
    def _evaluate(
        self,
        x: torch.Tensor,
        train_edge_index: torch.Tensor,
        val_edge_index: torch.Tensor
    ) -> float:
        """ê²€ì¦ AUC ê³„ì‚°"""
        from sklearn.metrics import roc_auc_score
        
        self.model.eval()
        with torch.no_grad():
            z = self.model.encode(x, train_edge_index)
            
            # Positive scores
            pos_scores = self.model.decode(z, val_edge_index)
            
            # Negative sampling for validation
            neg_edge_index = negative_sampling(
                edge_index=train_edge_index,
                num_nodes=x.shape[0],
                num_neg_samples=val_edge_index.shape[1]
            )
            neg_scores = self.model.decode(z, neg_edge_index)
            
            # AUC
            y_true = torch.cat([
                torch.ones(pos_scores.shape[0]),
                torch.zeros(neg_scores.shape[0])
            ]).cpu().numpy()
            
            y_score = torch.cat([pos_scores, neg_scores]).sigmoid().cpu().numpy()
            
            try:
                return roc_auc_score(y_true, y_score)
            except:
                return 0.5
    
    def predict_next_nodes(
        self,
        current_node_id: str,
        top_k: int = 5,
        exclude_learned: Optional[List[str]] = None
    ) -> List[Tuple[str, str, float]]:
        """
        í˜„ì¬ ë…¸ë“œì—ì„œ ë‹¤ìŒì— í•™ìŠµí•  ë…¸ë“œ ì˜ˆì¸¡
        
        Args:
            current_node_id: í˜„ì¬ í•™ìŠµí•œ ë…¸ë“œ ID
            top_k: ìƒìœ„ Kê°œ ë°˜í™˜
            exclude_learned: ì´ë¯¸ í•™ìŠµí•œ ë…¸ë“œ ID ë¦¬ìŠ¤íŠ¸
            
        Returns:
            [(node_id, node_title, score), ...] ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ
        """
        if self.model is None or self.graph_data is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if current_node_id not in self.graph_data.id_to_idx:
            raise ValueError(f"ë…¸ë“œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {current_node_id}")
        
        exclude_learned = exclude_learned or []
        current_idx = self.graph_data.id_to_idx[current_node_id]
        
        # ëª¨ë“  ë…¸ë“œì— ëŒ€í•œ ë§í¬ ì ìˆ˜ ê³„ì‚°
        self.model.eval()
        with torch.no_grad():
            z = self.node_embeddings
            
            # í˜„ì¬ ë…¸ë“œì—ì„œ ëª¨ë“  ë…¸ë“œë¡œì˜ ì ì¬ì  ì—£ì§€
            candidate_indices = [
                i for i in range(self.graph_data.num_nodes)
                if i != current_idx and 
                   self.graph_data.node_ids[i] not in exclude_learned
            ]
            
            if not candidate_indices:
                return []
            
            # ì—£ì§€ ì¸ë±ìŠ¤ ìƒì„±
            source_indices = [current_idx] * len(candidate_indices)
            target_indices = candidate_indices
            
            pred_edge_index = torch.tensor(
                [source_indices, target_indices],
                dtype=torch.long
            ).to(self.device)
            
            # ì ìˆ˜ ì˜ˆì¸¡
            scores = self.model.decode(z, pred_edge_index).sigmoid().cpu().numpy()
        
        # ìƒìœ„ Kê°œ ì„ íƒ
        results = []
        for idx, score in zip(candidate_indices, scores):
            results.append((
                self.graph_data.node_ids[idx],
                self.graph_data.node_titles[idx],
                float(score)
            ))
        
        # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        results.sort(key=lambda x: x[2], reverse=True)
        
        return results[:top_k]
    
    def save(self, path: str) -> None:
        """ëª¨ë¸ ì €ì¥"""
        torch.save({
            "model_state_dict": self.model.state_dict(),
            "config": {
                "embedding_dim": self.embedding_dim,
                "hidden_channels": self.hidden_channels,
                "out_channels": self.out_channels,
                "encoder_type": self.encoder_type,
                "decoder_type": self.decoder_type,
            }
        }, path)
        logger.info(f"ëª¨ë¸ ì €ì¥ë¨: {path}")
    
    def load(self, path: str, graph_data: GraphData) -> None:
        """ëª¨ë¸ ë¡œë“œ"""
        checkpoint = torch.load(path, map_location=self.device)
        
        self.graph_data = graph_data
        self.model = self._build_model(graph_data.embedding_dim)
        self.model.load_state_dict(checkpoint["model_state_dict"])
        self.model.eval()
        
        # ë…¸ë“œ ì„ë² ë”© ê³„ì‚°
        x = graph_data.x.to(self.device)
        edge_index = graph_data.edge_index.to(self.device)
        
        with torch.no_grad():
            self.node_embeddings = self.model.encode(x, edge_index)
        
        logger.info(f"ëª¨ë¸ ë¡œë“œë¨: {path}")


# =============================================================================
# Sanity Check
# =============================================================================

def run_sanity_check():
    """
    ì‘ì€ ìƒ˜í”Œ ê·¸ë˜í”„ì—ì„œ Lossê°€ ì¤„ì–´ë“œëŠ”ì§€ í™•ì¸í•˜ëŠ” Sanity Check
    """
    print("=" * 60)
    print("ğŸ§ª Link Prediction Sanity Check")
    print("=" * 60)
    
    # ìƒ˜í”Œ ê·¸ë˜í”„ ìƒì„± (5ê°œ ë…¸ë“œ)
    print("\nğŸ“Š ìƒ˜í”Œ ê·¸ë˜í”„ ìƒì„± (5ê°œ ë…¸ë“œ)...")
    graph_data = GraphDataLoader.create_sample_graph(
        num_nodes=5,
        embedding_dim=64,
        edge_probability=0.5
    )
    print(f"   ë…¸ë“œ ìˆ˜: {graph_data.num_nodes}")
    print(f"   ì—£ì§€ ìˆ˜: {graph_data.num_edges}")
    print(f"   ì„ë² ë”© ì°¨ì›: {graph_data.embedding_dim}")
    
    if graph_data.num_edges < 2:
        print("âš ï¸  ì—£ì§€ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤.")
        graph_data = GraphDataLoader.create_sample_graph(
            num_nodes=5,
            embedding_dim=64,
            edge_probability=0.7
        )
    
    # ëª¨ë¸ ìƒì„±
    print("\nğŸ”§ ëª¨ë¸ ìƒì„±...")
    predictor = LinkPredictor(
        embedding_dim=graph_data.embedding_dim,
        hidden_channels=32,
        out_channels=16,
        encoder_type="sage"
    )
    
    # í•™ìŠµ
    print("\nğŸ“ í•™ìŠµ ì‹œì‘ (50 ì—í¬í¬)...")
    history = predictor.train(
        graph_data,
        epochs=50,
        lr=0.01,
        verbose=False
    )
    
    # Loss ê°ì†Œ í™•ì¸
    initial_loss = history["train_loss"][0]
    final_loss = history["train_loss"][-1]
    loss_reduced = final_loss < initial_loss
    
    print(f"\nğŸ“ˆ í•™ìŠµ ê²°ê³¼:")
    print(f"   ì´ˆê¸° Loss: {initial_loss:.4f}")
    print(f"   ìµœì¢… Loss: {final_loss:.4f}")
    print(f"   Loss ê°ì†Œ: {'âœ… YES' if loss_reduced else 'âŒ NO'} ({initial_loss - final_loss:.4f})")
    
    # ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    print("\nğŸ”® ë‹¤ìŒ í•™ìŠµ ë…¸ë“œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸:")
    current_node = graph_data.node_ids[0]
    predictions = predictor.predict_next_nodes(current_node, top_k=3)
    
    for node_id, title, score in predictions:
        print(f"   â†’ {title}: {score:.3f}")
    
    # ê²°ê³¼ íŒì •
    print("\n" + "=" * 60)
    if loss_reduced and predictions:
        print("ğŸ‰ Sanity Check PASSED!")
    else:
        print("âŒ Sanity Check FAILED")
    print("=" * 60)
    
    return loss_reduced


if __name__ == "__main__":
    run_sanity_check()
